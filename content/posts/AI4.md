---
title: "Thoughts for Navigating Bias in AI Policy"
date: 2023-08-28T15:02:26+12:00
draft: false
tags: ["ai ethics"]
categories: ["tech"]
---

In this article, we explore the contents of the research paper titled ["Power and Politics in Framing Bias in Artificial Intelligence Policy"](https://onlinelibrary.wiley.com/doi/10.1111/ropr.12567).

### Approach to Mitigating the Harms of Bias That Appears Most Viable

The article highlights a social approach aimed at increasing the diversity of the AI workforce. Specifically, it suggests that "more diverse academic disciplines should be involved, including philosophers, social scientists, legal theorists, and political scientists who can bring their long-standing expertise."

Additionally, there is a need to build a more inclusive workplace culture so that women and minorities feel supported and included in the conversation.		Additionally, there is a need to foster a more inclusive workplace culture, ensuring that women and minorities feel supported and included in the conversation.

### What Types of Bias Might Not Be Addressed by the Identified the Social Approach?

The social approach does not effectively address bias introduced by the data consumed by AI models. These models learn from large datasets that may contain biases from the past or the internet, including racism, misogyny, and sexism. Despite our improved understanding, learning from biased historical data can lead AI to make biased decisions, hindering progress toward a fairer society. The social approach primarily focuses on addressing bias within the minds of those working on AI products but does not directly tackle the bias inherent in the AI's training data.

### Approach to Mitigating the Harms of Bias That the Article Suggests Appears Least Viable

The article presents a technical approach as a solution, suggesting that "AI can be the solution to human bias and can help detect and eliminate it." This involves "improving data quality and reliability and designing better algorithms." However, hastily resorting to technical solutions may not be the best approach, as it may overlook the complexity of bias in AI and pushes away the opportunity to treat this as a wicked problem. Bias has deep historical roots and resurfaces through AI systems, making it a complex problem that cannot be fully addressed with technical fixes alone*.

While some documents demonstrate how AI systems can be designed to be fairer and more equitable than humans**, there are also studies indicating that "AI can exacerbate human biases when training data, algorithms, and other design choices reflect and amplify existing cultural assumptions and inequalities."*** Therefore, the effectiveness of a purely technical approach remains a subject of debate.

References:
- *BIC/APPGAI (Big Innovation Centre/All-Party Parliamentary Group on Artificial Intelligence) (2017b). Governance, Social, and Organizational Perspective for AI. Big Innovation Centre.
- **IEEE (Institute of Electrical and Electronics Engineers) (2017). Ethically aligned design. A vision for prioritizing human well-being with autonomous and intelligent systems. Version 2. IEEE. Accessed June 1, 2023. [Link](https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf).
- ***Campolo, A, M. Sanfilippo, M. Whittaker, and K. Crawford (2017). AI Now 2017 Report. AI Now Institute, New York University. Accessed June 1, 2023. [Link](https://ainowinstitute.org/publication/ai-now-2017-report-2).